# Coursera Natural Language Processing Specialization

This repository contains material related to Coursera [Natural Language Processing Specialization](https://www.coursera.org/specializations/natural-language-processing). It consists of a bunch of Jupyter notebooks for each weekly assignment.

## Content

### Natural Language Processing with Classification and Vector Spaces

* [Sentiment Analysis with Logistic Regression](https://github.com/naderabdalghani/coursera-natural-language-processing-specialization/tree/main/1.%20Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces/Week1): Learn to extract features from text into numerical vectors, then build a binary classifier for tweets using logistic regression.
* [Sentiment Analysis with Na√Øve Bayes](https://github.com/naderabdalghani/coursera-natural-language-processing-specialization/tree/main/1.%20Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces/Week2): Learn the theory behind Bayes' rule for conditional probabilities, then apply it toward building a Naive Bayes tweet classifier.
* [Vector Space Models](https://github.com/naderabdalghani/coursera-natural-language-processing-specialization/tree/main/1.%20Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces/Week3): Vector space models capture semantic meaning and relationships between words. Learn how to create word vectors that capture dependencies between words, then visualize their relationships in two dimensions using PCA.
* [Machine Translation and Document Search](https://github.com/naderabdalghani/coursera-natural-language-processing-specialization/tree/main/1.%20Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces/Week4): Learn to transform word vectors and assign them to subsets using locality sensitive hashing, in order to perform machine translation and document search.

### Natural Language Processing with Probabilistic Models

### Natural Language Processing with Sequence Models

### Natural Language Processing with Attention Models
